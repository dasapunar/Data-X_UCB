{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2018: Homework 02\n",
    "\n",
    "### Regression, Classification, Webscraping\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3), Alexander Fred-Ojala (Extra Credit)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction-classification, regression and web-scraping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is uploaded to bCourses and is named: __Energy.csv__\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1:Read the data file in python. Describe data features in terms of type, distribution range and mean values. Plot feature distributions.This step should give you clues about data sufficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of each variable.\n",
    "# Reading FileD\n",
    "df = pd.read_csv('Energy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing data (General)\n",
    "print(\"Describing Data in a general view...\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data features in terms of type, distribution range and mean values.\n",
    "\n",
    "def nice_display_basic_statistics(maxi, mini, mean):\n",
    "    \"\"\"\n",
    "    Print in a nice way the data features distribution range and mean values\n",
    "\n",
    "    Arguments:\n",
    "        maxi -- python float containing the Max of the feature\n",
    "        mini -- python float containing the Min of the feature\n",
    "        mean -- python float containing the Mean of the feature\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Max: \", maxi)\n",
    "    print(\"Min: \", mini)\n",
    "    print(\"Mean\", mean)\n",
    "        \n",
    "        \n",
    "def nice_display(column_name, dtype, maxi, mini, mean):\n",
    "    \"\"\"\n",
    "    Print in a nice way the data features in terms of type, distribution range and mean values\n",
    "\n",
    "    Arguments:\n",
    "        column_name -- python string containing the name of the feature\n",
    "        dtype -- python string containing the dtype of the feature\n",
    "        maxi -- python float containing the Max of the feature\n",
    "        mini -- python float containing the Min of the feature\n",
    "        mean -- python float containing the Mean of the feature\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if dtype == \"float64\":        \n",
    "        print(\"The feature \" + column_name + \": \")\n",
    "        print(\"Type: Float so is Continuous!\")\n",
    "        nice_display_basic_statistics(maxi, mini, mean)\n",
    "              \n",
    "    else:\n",
    "        print(\"The feature \" + column_name + \": \")\n",
    "        print(\"Type: Integer so is Continuous!\")\n",
    "        nice_display_basic_statistics(maxi, mini, mean)\n",
    "        \n",
    "    print(\"-\" * 30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data features in terms of type, distribution range and mean values.\n",
    "for i in df.columns:\n",
    "    nice_display(i, df[i].dtype, df[i].max(), df[i].min(), df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of each variable.\n",
    "\n",
    "f = plt.figure()\n",
    "\n",
    "# Specify the grid\n",
    "ax1 = plt.subplot2grid((3,3), (0,0))\n",
    "ax2 = plt.subplot2grid((3,3), (0,1)) \n",
    "ax3 = plt.subplot2grid((3,3), (0,2))\n",
    "ax4 = plt.subplot2grid((3,3), (1,0))\n",
    "ax5 = plt.subplot2grid((3,3), (1,1))\n",
    "ax6 = plt.subplot2grid((3,3), (1,2))\n",
    "ax7 = plt.subplot2grid((3,3), (2,0)) \n",
    "ax8 = plt.subplot2grid((3,3), (2,1))\n",
    "ax9 = plt.subplot2grid((3,3), (2,2))\n",
    "\n",
    "ax1.hist(df[\"X1\"], color=\"Green\")\n",
    "ax2.hist(df[\"X2\"], color=\"Blue\")\n",
    "ax3.hist(df[\"X3\"], color=\"Orange\")\n",
    "ax4.hist(df[\"X4\"], color=\"Yellow\")\n",
    "ax5.hist(df[\"X5\"], color=\"Purple\")\n",
    "ax6.hist(df[\"X6\"], color=\"Black\")\n",
    "ax7.hist(df[\"X7\"], color=\"Red\")\n",
    "ax8.hist(df[\"X8\"], color=\"Magenta\")\n",
    "ax9.hist(df[\"Y1\"], color=\"Cyan\")\n",
    "\n",
    "# Add titles\n",
    "ax1.set_title('X1')\n",
    "ax2.set_title('X2')\n",
    "ax3.set_title('X3')\n",
    "ax4.set_title('X4')\n",
    "ax5.set_title('X5')\n",
    "ax6.set_title('X6')\n",
    "ax7.set_title('X7')\n",
    "ax8.set_title('X8')\n",
    "ax9.set_title('Y1')\n",
    "\n",
    "\n",
    "f.suptitle('Feature Distributions!',fontsize=20, y=1.1) # y location\n",
    "\n",
    "f.tight_layout()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adittional INFO\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More graphs (with another method)\n",
    "df.hist(figsize=(13,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relations between features\n",
    "pd.tools.plotting.scatter_matrix(df,figsize=(13,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "LABELS ARE CONTINUOUS VALUES.\n",
    "Here the model is trained to predict a continuous value for each instance.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a continuous value  for  that instance.  \n",
    "\n",
    "__Q2.1: Train a linear regression model on 85 percent of the given dataset, what is the intercept value and coefficient values.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE data.\n",
    "data = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs\n",
    "print('Number of NaNs in the dataframe:\\n',data.isnull().sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X from the Data Set.\n",
    "X=data.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Labels from the Data Set.\n",
    "Y=data['Y1']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are my shapes?\n",
    "print(\"Feature vector shape=\", X.shape)\n",
    "print(\"Class shape=\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Training and Validation set  using sklearn function.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train))\n",
    "print ('Number of samples in validation data:',len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name our Logistic Regression object.\n",
    "LinearRegressionModel= LinearRegression()\n",
    "\n",
    "LinearRegressionModel.fit(x_train, y_train)\n",
    "Z_train=LinearRegressionModel.predict(x_train)\n",
    "Z_test = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "# The Coefficients.\n",
    "print('Coefficients:', LinearRegressionModel.coef_)\n",
    "\n",
    "# The Interception.\n",
    "print('Intercept:', LinearRegressionModel.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### Q.2.2: Report model performance using 'ROOT MEAN SQUARE' error metric on:  \n",
    "__1. Data that was used for training(Training error)__   \n",
    "__2. On the 15 percent of unseen data (test error) __ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error and Accuracy for Training and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Mean Squared Error.\n",
    "print(\"Mean squared error of training:\",np.mean((Z_train - y_train) ** 2))\n",
    "print(\"Mean squared error of test:\",np.mean((Z_test - y_test) ** 2))\n",
    "\n",
    "# The Accuracy for Training and Test.\n",
    "print(\"Accuracy for Training: \", LinearRegressionModel.score(x_train, y_train)* 100, \"%\")\n",
    "print(\"Accuracy for Test\", LinearRegressionModel.score(x_test, y_test) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__ Q2.3: Lets us see the effect of amount of data on the performance of prediction model.Use varying amounts of  Training data (100,200,300,400,500,all) to train regression models and report  training error and validation error in each case. Validation data/Test data   is the same as above for  all  these cases.__  \n",
    "\n",
    "Plot error rates vs number of training examples.Comment on the relationshipyou observe in the plot, between the amount of data used to train the model and the validation accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Experiments ASSUMING THAT THE QUESTION AIM TO THE AMOUNT OF DATA CORRESPONDS TO THE WHOLE DATA SET! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_experiments(X, Y, amount_training_data, costs_train, costs_test, variances, biases):\n",
    "    \"\"\"\n",
    "    Print in a nice way the experiment.\n",
    "\n",
    "    Arguments:\n",
    "        X -- Pandas Dataframe. X whole Data Set.\n",
    "        Y -- Pandas Dataframe. Labels of the Data Set.\n",
    "        amount_training_data -- Integer. Number of rows of the Training Set (n_x).\n",
    "        costs_train -- List Object. Array with all the costs (square mean error) in the \n",
    "                       Training Set of the different experiments.\n",
    "        costs_test -- List Object. Array with all the costs (square mean error) in the\n",
    "                      Test Set of the different experiments\n",
    "        variances -- List Object. Array with the variances between Train and Test of \n",
    "                     the different experiments.\n",
    "        biases -- List Object. Array with the biases (Testing Accuracy) between Train \n",
    "                  and Test of the different experiments.\n",
    "\n",
    "    Return:\n",
    "        costs_train -- List Object. Array with all the costs (square mean error) in the \n",
    "                       Training Set of the different experiments.\n",
    "        costs_test -- List Object. Array with all the costs (square mean error) in the\n",
    "                      Test Set of the different experiments\n",
    "        variances -- List Object. Array with the variances between Train and Test of \n",
    "                     the different experiments.\n",
    "        biases -- List Object. Array with the biases (Testing Accuracy) between Train \n",
    "                  and Test of the different experiments.        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    error_test = 0\n",
    "    \n",
    "    # For beatiful display.\n",
    "    print(\"-\"*20, \"AMOUNT OF TRAINING DATA: \", amount_training_data, \" -\"*20)\n",
    "    \n",
    "    # Spliting with the Amount Of Training Data.\n",
    "    percentage = amount_training_data/X.shape[0]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1-percentage, random_state=40)\n",
    "    print ('Number of samples in training data:',len(x_train))\n",
    "    print ('Number of samples in validation data:',len(x_test))\n",
    "    \n",
    "    # Name our logistic regression object.\n",
    "    LinearRegressionModel= LinearRegression()\n",
    "\n",
    "    # Fit Model. \n",
    "    LinearRegressionModel.fit(x_train, y_train)\n",
    "    \n",
    "    # Calculate Predict Vector for Train.\n",
    "    Z_train=LinearRegressionModel.predict(x_train)\n",
    "\n",
    "    # The Coefficients.\n",
    "    print('Coefficients:', LinearRegressionModel.coef_)\n",
    "    \n",
    "    # The Interception.\n",
    "    print('Intercept:', LinearRegressionModel.intercept_)\n",
    "    \n",
    "    # The mean squared error for Train.\n",
    "    error_train = np.mean((Z_train - y_train) ** 2)\n",
    "    print(\"Mean squared error of training:\",error_train)\n",
    "    \n",
    "    # Costs, Bias or Accuracy for Training Set.\n",
    "    costs_train.append(error_train)\n",
    "    bias = LinearRegressionModel.score(x_train, y_train)* 100\n",
    "    biases.append(bias)\n",
    "    \n",
    "    # For the border case that we don't have Test Set, the Training Set have the whole Data Set.\n",
    "    if amount_training_data != X.shape[0]:\n",
    "        # Calculate Predict Vector for Test.\n",
    "        Z_test = LinearRegressionModel.predict(x_test)\n",
    "        \n",
    "        # The mean squared error for Test.\n",
    "        error_test = np.mean((Z_test - y_test) ** 2)\n",
    "        costs_test.append(error_test)\n",
    "        print(\"Mean squared error of test:\",error_test)\n",
    "        \n",
    "        # Costs, Bias or Accuracy for Test Set.\n",
    "        test_accuracy = LinearRegressionModel.score(x_test, y_test) * 100\n",
    "        variance =  bias - test_accuracy\n",
    "        variances.append(variance)\n",
    "        print(\"Accuracy for Test\", test_accuracy, \"%\")\n",
    "        print(\"Variance: \", variance, \"\\n\")\n",
    "    \n",
    "    # Printing Accuracy for Training.\n",
    "    print(\"Accuracy for Training: \", bias, \"%\")\n",
    "\n",
    "    return costs_train, costs_test, variances, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I AM ASSUMING THAT THE QUESTION AIM TO THE AMOUNT OF DATA CORRESPONDS TO THE WHOLE DATA SET! :)\n",
    "\n",
    "costs_train = []\n",
    "costs_tests = []\n",
    "variances = []\n",
    "biases = []\n",
    "\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,100, costs_train, costs_tests, variances, biases)\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,200, costs_train, costs_tests, variances, biases)\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,300, costs_train, costs_tests, variances, biases)\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,400, costs_train, costs_tests, variances, biases)\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,500, costs_train, costs_tests, variances, biases)\n",
    "costs_train, costs_tests, variances, biases = different_experiments(X,Y,X.shape[0], costs_train, costs_tests, variances, biases)\n",
    "\n",
    "plt.plot(costs_train)\n",
    "plt.plot(costs_tests)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('amount of training data (per hundreds)')\n",
    "plt.title(\"MEAN SQUARED BY EXPERIMENT\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(variances)\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('amount of training data (per hundreds)')\n",
    "plt.title(\"VARIANCE BY EXPERIMENT\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(biases)\n",
    "plt.ylabel('bias')\n",
    "plt.xlabel('amount of training data (per hundreds)')\n",
    "plt.title(\"BIAS BY EXPERIMENT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  \n",
    "\n",
    "__ Q 3.1:  Bucket values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:__ \n",
    "\n",
    "0: 'Low' ( < 15),   \n",
    "1: 'Medium'  (15-30),   \n",
    "2: 'High'  (>30)\n",
    "\n",
    "This converts the given dataset  into a classification problem, classes being, Heating load is: *low, medium or high*. Use this datset with transformed 'heating load' for creating a  logistic regression classifiction model that predicts heating load type of a building. Use test-train split ratio of 0.15.  \n",
    "\n",
    "*Report training and test accuracies and  confusion matrices.*\n",
    "\n",
    "\n",
    "**HINT:** Use pandas.cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the data Frame with the corresponding new Labels.\n",
    "df[\"Y1\"] = pd.cut(df[\"Y1\"], bins=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data and storage in new variable \"data2\", since we are in the same Part I.\n",
    "data2= shuffle(df).reset_index(drop=True)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs\n",
    "print('Number of NaNs in the dataframe2:\\n',data2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data.\n",
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature distribution of each continuous valued feature\n",
    "data2.hist(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X from the Data Set.\n",
    "X2=data2.iloc[:,:-1]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Labels from the Data Set.\n",
    "Y2=data2['Y1']\n",
    "Y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many values I have in each Label?\n",
    "Y2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps Label to integers\n",
    "    # - Low: 0\n",
    "    # - High: 1\n",
    "    # - Medium : 2\n",
    "Y2=Y2.map({'Low': 0, 'High': 1,'Medium' :2})\n",
    "print (Y2.value_counts()) \n",
    "\n",
    "# Show how is my Label array.\n",
    "Y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are my shapes?\n",
    "print(\"Feature vector shape=\", X2.shape)\n",
    "print(\"Class shape=\", Y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Training Set and Validation Set  using sklearn function. \n",
    "# Storage the different Data with the label \"2\", since we are in the same Part I.\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train2))\n",
    "print ('Number of samples in validation data:',len(x_test2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name our Logistic Regression object\n",
    "LogisticRegressionModel = LogisticRegression()\n",
    "\n",
    "# Train the Model\n",
    "LogisticRegressionModel.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuracy: Float in the variable: training_accuracy2 \n",
    "training_accuracy2 = LogisticRegressionModel.score(x_train2,y_train2)\n",
    "print ('Training Accuracy:',training_accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction2 of Train.\n",
    "prediction_train2 = LogisticRegressionModel.predict(x_train2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_error(real_label,predicted_label):\n",
    "    \"\"\"\n",
    "    Find the error between Prediction and \"Real Label\".\n",
    "\n",
    "    Arguments:\n",
    "        real_label -- label in data\n",
    "        predicted_label -- label predicted by the model\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Empty array of Zeros, with the length of \"real_label\"\n",
    "    Loss_Array = np.zeros(len(real_label))\n",
    "    \n",
    "    for i,value in enumerate(real_label):\n",
    "        \n",
    "        if value == predicted_label[i]: \n",
    "            Loss_Array[i] = 0\n",
    "        else:\n",
    "            Loss_Array[i] = 1\n",
    "\n",
    "    print (\"Y-realLabel   Z-predictedLabel   Error \\n\")\n",
    "    for i,value in enumerate(real_label):\n",
    "        print (value,\"\\t\\t\" ,predicted_label[i],\"\\t\\t\",Loss_Array[i])\n",
    "        \n",
    "    error_rate = np.average(Loss_Array)\n",
    "    print (\"\\nThe error rate is \", error_rate)\n",
    "    print ('\\nThe accuracy of the model is ',1-error_rate )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error of Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_error(y_train2, prediction_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Validation Accuracy and Variance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy: Float in the variable: validation_accuracy2 \n",
    "validation_accuracy2 = LogisticRegressionModel.score(x_test2,y_test2)\n",
    "print('Accuracy of the model on unseen validation data: ',validation_accuracy2)\n",
    "\n",
    "# Variance: Float. Difference between Training and Test.\n",
    "variance2 = training_accuracy2 - validation_accuracy2\n",
    "print(\"Variance: \", variance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of Test.\n",
    "y_pred2 = LogisticRegressionModel.predict(x_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion Matrix. We're looking for the Diagonal.\n",
    "ConfusionMatrix = pd.DataFrame(confusion_matrix(y_test2, y_pred2),columns=['Predicted 0','Predicted 1','Predicted 2'],index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Q3.2: One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. This makes training less sensitive to the scale of features . Scaling is important in algorithms that use distance based classification, SVM or K means or involve gradient descent optimization.If we  Scale features in the range [0,1] it is called unity based normalization.__\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "more at: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Processing with the Same Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "print(x_train2.head())\n",
    "\n",
    "df.rename(index=str, columns={\"A\": \"a\", \"B\": \"c\"})\n",
    "x_scaled = pd.DataFrame(preprocessing.scale(X2)).rename(index=str, columns={  0: \"X1\", \n",
    "                                                                              1: \"X2\",\n",
    "                                                                              2: \"X3\",\n",
    "                                                                              3: \"X4\",\n",
    "                                                                              4: \"X5\",\n",
    "                                                                              5: \"X6\",\n",
    "                                                                              6: \"X7\",\n",
    "                                                                              7: \"X8\"})\n",
    "print(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are my shapes?\n",
    "print(\"Feature vector shape=\", x_scaled.shape)\n",
    "print(\"Class shape=\", Y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Training Set and Validation Set  using sklearn function. \n",
    "# Storage the different Data with the label \"3\", since we are in the same Part I.\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x_scaled, Y2, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train3))\n",
    "print ('Number of samples in validation data:',len(x_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Scaled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name our Logistic Regression object. With the\n",
    "LogisticRegressionModel2 = LogisticRegression()\n",
    "\n",
    "# Train the Model\n",
    "LogisticRegressionModel2.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuracy: Float in the variable: training_accuracy3\n",
    "training_accuracy3 = LogisticRegressionModel2.score(x_train3,y_train3)\n",
    "print ('Training Accuracy:',training_accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction in Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction3 in Train.\n",
    "prediction_train3 = LogisticRegressionModel2.predict(x_train3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error of Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find error:\n",
    "find_error(y_train3, prediction_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Validation Accuracy and Variance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy: Float in the variable: validation_accuracy3\n",
    "validation_accuracy3 = LogisticRegressionModel2.score(x_test3,y_test3)\n",
    "print('Accuracy of the model on unseen validation data: ',validation_accuracy3)\n",
    "\n",
    "# Variance: Float. Difference between Training and Test.\n",
    "variance3 = training_accuracy3 - validation_accuracy3\n",
    "print(\"Variance: \", variance3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction in Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction3 in Test.\n",
    "y_pred3 = LogisticRegressionModel2.predict(x_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion Matrix. We're looking for the Diagonal.\n",
    "ConfusionMatrix2 = pd.DataFrame(confusion_matrix(y_test3, y_pred3),columns=['Predicted 0','Predicted 1','Predicted 2'],index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison Two Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accurracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accurracy Comparison\n",
    "experiments_t = (\"Original Model\", \"Scaled Model\")\n",
    "accuracies_t = [training_accuracy2, training_accuracy3]\n",
    " \n",
    "plt.bar(np.arange(len(experiments_t)), accuracies_t, align='center', alpha=1)\n",
    "plt.xticks(np.arange(len(experiments_t)), experiments_t)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Training Accurracy Comparison')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Accurracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accurracy Comparison\n",
    "experiments_v = (\"Original Model\", \"Scaled Model\")\n",
    "accuracies_v = [validation_accuracy2, validation_accuracy3]\n",
    " \n",
    "plt.bar(np.arange(len(experiments_v)), accuracies_v, align='center', alpha=1)\n",
    "plt.xticks(np.arange(len(experiments_v)), experiments_v)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accurracy Comparison')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variances Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variances Comparison\n",
    "experiments = (\"Original Model\", \"Scaled Model\")\n",
    "variances = [variance2, variance3]\n",
    " \n",
    "plt.bar(np.arange(len(experiments)), variances, align='center', alpha=1)\n",
    "plt.xticks(np.arange(len(experiments)), experiments)\n",
    "plt.ylabel('Variances')\n",
    "plt.title('Variances Comparison')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. Analyze the data features, check for NaN values. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading FileD\n",
    "df = pd.read_csv('diabetesdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis of the Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing data (General)\n",
    "print(\"Describing Data in a general view...\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data features in terms of type, distribution range and mean values.\n",
    "for i in df.columns:\n",
    "    nice_display(i, df[i].dtype, df[i].max(), df[i].min(), df[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adittional INFO\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions for each feature\n",
    "df.hist(figsize=(13,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relations between features\n",
    "pd.tools.plotting.scatter_matrix(df,figsize=(13,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE data.\n",
    "data = shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced data set?\n",
    "data['IsDiabetic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Bayes Error for prediction accuracy\n",
    "_[0]/(sum(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs\n",
    "print('Number of NaNs in the dataframe:\\n',data.isnull().sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__ 2. Preprocess data to replace NaN values in a feature(if any) using mean of the feature.  \n",
    "Train  logistic regression, SVM, perceptron, kNN, xgboost and random forest models using this preprocessed data with 20% test split.Report training and test accuracies.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data to replace NaN values in a feature(if any) using mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"glucoseLevel\"]= data[\"glucoseLevel\"].fillna(data[\"glucoseLevel\"].mean())\n",
    "data[\"Age\"]= data[\"Age\"].fillna(data[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs again.\n",
    "print('Number of NaNs in the dataframe:\\n',data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X from the Data Set.\n",
    "X=data.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Labels from the Data Set.\n",
    "Y=data['IsDiabetic']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which are my shapes?\n",
    "print(\"Feature vector shape=\", X.shape)\n",
    "print(\"Class shape=\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train))\n",
    "print ('Number of samples in validation data:',len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_flow(Model, x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Print all the flow of a model: Fit, Training Accuracy, Error by Example, Validation Accuracy and Variance.\n",
    "\n",
    "    Arguments:\n",
    "        x_train -- Pandas Dataframe. Features Training Set.\n",
    "        x_test -- Pandas Dataframe. Features Test Set.\n",
    "        y_train -- Pandas Dataframe. Label Train Set.\n",
    "        y_test -- Pandas Dataframe. Label Test Set.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Train the Model\n",
    "    Model.fit(x_train, y_train)\n",
    "    \n",
    "    # Training Accuracy\n",
    "    training_accuracy = Model.score(x_train, y_train)\n",
    "    print ('Training Accuracy:',training_accuracy)\n",
    "\n",
    "    # Prediction of Train.\n",
    "    prediction_train = Model.predict(x_train) \n",
    "\n",
    "    # Find Error\n",
    "    find_error(y_train, prediction_train)\n",
    "\n",
    "    # Validation Accuracy\n",
    "    validation_accuracy = Model.score(x_test,y_test)\n",
    "    print('Accuracy of the model on unseen validation data: ',validation_accuracy)\n",
    "\n",
    "    # Prediction of Test.\n",
    "    y_pred = Model.predict(x_test)\n",
    "\n",
    "    # Variance: Float. Difference between Training and Test.\n",
    "    variance = training_accuracy - validation_accuracy\n",
    "    print(\"Variance: \", variance)\n",
    "    \n",
    "    \n",
    "def different_models(model_name, x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Differentiate models and call model_flow function\n",
    "\n",
    "    Arguments:\n",
    "        model_name -- Python String. Corresponding to the model name.\n",
    "        x_train -- Pandas Dataframe. Features Training Set.\n",
    "        x_test -- Pandas Dataframe. Features Test Set.\n",
    "        y_train -- Pandas Dataframe. Label Train Set.\n",
    "        y_test -- Pandas Dataframe. Label Test Set.\n",
    "        \n",
    "    \"\"\"\n",
    "    if model_name == \"LogisticRegression\":\n",
    "        # Model Object\n",
    "        model = LogisticRegression()\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)\n",
    "       \n",
    "    elif model_name == \"SVM\":\n",
    "        # Model Object\n",
    "        model = SVC()\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    elif model_name == \"Perceptron\":\n",
    "        # Model Object\n",
    "        model = Perceptron()\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    elif model_name == \"kNN\":\n",
    "        # Model Object\n",
    "        model = KNeighborsClassifier(n_neighbors = 2)\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    elif model_name == \"xgboost\":\n",
    "        # Model Object\n",
    "        model = xgb.XGBClassifier(n_estimators=1000)\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    elif model_name == \"random forest\":\n",
    "        # Model Object\n",
    "        model = RandomForestClassifier(n_estimators=1000)\n",
    "        model_flow(model, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"LogisticRegression\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"SVM\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"Perceptron\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"kNN\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"xgboost\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"random forest\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__3. What is the  ratio of diabetic persons in 3 equirange bands of 'BMI' and 'Pedigree' in the provided dataset.__\n",
    "\n",
    " __Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut features: BP, insulin, BMI & Pedigree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"BP\"] = pd.cut(data[\"BP\"], bins=3, labels=[0, 1, 2])\n",
    "data[\"insulin\"] = pd.cut(data[\"insulin\"], bins=3, labels=[0, 1, 2])\n",
    "data[\"BMI\"] = pd.cut(data[\"BMI\"], bins=3, labels=[0, 1, 2])\n",
    "data[\"Pedigree\"] = pd.cut(data[\"Pedigree\"], bins=3, labels=[0, 1, 2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP Ratio\n",
    "data[[\"BP\", \"IsDiabetic\"]].groupby([\"BP\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insulin Ratio\n",
    "data[[\"insulin\", \"IsDiabetic\"]].groupby([\"insulin\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI Ratio\n",
    "data[[\"BMI\", \"IsDiabetic\"]].groupby([\"BMI\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedigree Ratio\n",
    "data[[\"Pedigree\", \"IsDiabetic\"]].groupby([\"Pedigree\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__4. Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group.We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create Guess Matrix for Age and glucoseLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs.\n",
    "print('Number of NaNs in the dataframe:\\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BP\"] = pd.cut(df[\"BP\"], bins=3, labels=[0, 1, 2])\n",
    "df[\"insulin\"] = pd.cut(df[\"insulin\"], bins=3, labels=[0, 1, 2])\n",
    "df[\"BMI\"] = pd.cut(df[\"BMI\"], bins=3, labels=[0, 1, 2])\n",
    "df[\"Pedigree\"] = pd.cut(df[\"Pedigree\"], bins=3, labels=[0, 1, 2])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_age = np.zeros((3,3),dtype=int) # Initialize Matrix\n",
    "guess_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_glucose_level = np.zeros((3,3),dtype=int) # Initialize Matrix\n",
    "guess_glucose_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        aux_age = df[(df['BMI'] == i) & (df['BP'] == j)]['Age'].dropna().median()\n",
    "        guess_age[i,j] = int(aux_age)\n",
    "        \n",
    "        aux_glucose_level = df[(df['BP'] == i) & (df['Pedigree'] == j)]['glucoseLevel'].dropna().median()\n",
    "        guess_glucose_level[i,j] = int(aux_glucose_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess Age Matrix\n",
    "guess_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess Glucose Level Matrix\n",
    "guess_glucose_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN Values of Age with the Guess Age Matrix\n",
    "for i in range(0, 3):\n",
    "        for j in range(0, 3):\n",
    "            df.loc[ (df[\"Age\"].isnull()) & (df['BMI'] == i)& (df['BP'] == j),'Age'] = guess_age[i,j]\n",
    "                    \n",
    "\n",
    "df['Age'] = df['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN Values of Age with the Guess Age Matrix\n",
    "for i in range(0, 3):\n",
    "        for j in range(0, 3):\n",
    "            df.loc[ (df[\"glucoseLevel\"].isnull()) & (df['BP'] == i) & \\\n",
    "                   (df['Pedigree'] == j),'glucoseLevel'] = guess_age[i,j]\n",
    "                    \n",
    "\n",
    "df['glucoseLevel'] = df['glucoseLevel'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NaNs, to probe my proccedure above\n",
    "print('Number of NaNs in the dataframe:\\n',df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__5. Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 5 categories each.__\n",
    "\n",
    "__Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 20% test split. Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Pre-Processing: Make glucoseLevel and Age categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = pd.cut(df[\"Age\"], bins=5, labels=[0, 1, 2, 3, 4])\n",
    "df[\"glucoseLevel\"] = pd.cut(df[\"glucoseLevel\"], bins=5, labels=[0, 1, 2, 3, 4])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X from the Data Set.\n",
    "X=df.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Labels from the Data Set.\n",
    "Y=df['IsDiabetic']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train))\n",
    "print ('Number of samples in validation data:',len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"Perceptron\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"LogisticRegression\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_models(\"random forest\", x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "1. __Derive the expression for the optimal parameters in the linear regression equation, i.e. solve the normal equation for Ordinary Least Squares for the case of Simple Linear Regression, when we only have one input and one output__\n",
    "\n",
    "Given a set of _n_ points $(X_i,Y_i)$ where $Yi$ is dependent on $Xi$ by a linear relation,  find the best-fit line,$$Z_i = {aX_i + b}$$  that minimizes the __sum of squared errors in Y__,i.e: $$minimize \\sum_{i}{(Y_i- Z_i)^2}$$\n",
    "__i. __ Show that $$ intercept \\quad b = \\overline{Y}-  a.\\overline{X}\\quad  and   \\quad slope \\quad a= \\frac{\\sum_{i}(X_i- \\overline{X})\u0001(Y_i- \\overline{Y})^2}{ \\sum_{i}(X_i- \\overline{X})}$$\n",
    "\n",
    "\n",
    " where $\\overline{X}$ and  $\\overline{Y}$ are the averages of the X values and the Y values, respectively.\n",
    " \n",
    "__ ii. __Show that slope _a_ can be written as $ a = r.(S_y /S_x)$ where $S_y$  = the standard deviation of the Y values and $S_x$= the standard deviation of the X values and _r_ is the correlation coefficient.\n",
    "\n",
    "##### Please try to write a nice LateXed version of your answer, and do the derivations of the expressions as nicely as possible\n",
    "\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i.\n",
    "$$ (1) \\ \\ Z_i = {aX_i + b} \\\\\n",
    "   (2) \\ \\ \\sum_{i}{(Y_i- Z_i)^2}\n",
    "$$\n",
    "\n",
    "Replace (1) in (2)\n",
    "\n",
    "$$ (3) \\ \\ \\sum_{i}{(Y_i- {(aX_i + b)})^2} \\\\\n",
    "   (4) \\ \\ \\sum_{i}{(Y_i- aX_i - b)^2}\n",
    "$$\n",
    "\n",
    "We partial derivate (4) by b:\n",
    "$$\n",
    "   (5) \\ \\ \\sum_{i}{2 * (Y_i- aX_i - b) * (-1)}\\\\\n",
    "   (6) \\ \\ \\sum_{i}{ -2Y_i + 2aX_i + 2b}\n",
    "$$\n",
    "\n",
    "We (6) = 0\n",
    "$$\n",
    "   (7) \\ \\ \\sum_{i}{ -2Y_i + 2aX_i + 2b} = 0 \\\\\n",
    "   (8) \\ \\ b = \\sum_{i}{ Y_i - aX_i}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "$$\n",
    "    b = \\overline{Y} - a\\overline{X} \\\\\n",
    "    \\blacksquare\n",
    "$$\n",
    "\n",
    "To find the Slope a we partial derivate (4) by a and = 0\n",
    "$$\n",
    "    (9) \\ \\ \\sum_{i}{2 * (Y_i- aX_i - b) * (-X_i)} = 0\\\\\n",
    "    (10) \\ \\ \\sum_{i}{(-Y_iX_i + aX_i^2 + X_i\\overline{Y} - aX_i\\overline{X})} = 0\n",
    "$$\n",
    "Then we free a\n",
    "\n",
    "$$\n",
    "    \\quad a= \\frac{\\sum_{i}(X_i- \\overline{X})\u0001(Y_i- \\overline{Y})^2}{ \\sum_{i}(X_i- \\overline{X})} \\\\\n",
    "    \\blacksquare\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Extra Credit Points: Fun with Webscraping & Text manipulation\n",
    "### (Mandatory for Grad students!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'> `NOTE:` **If you are a Graduate Section student (enrolled in 290), the Extra Credit Questions are mandatory.**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Statistics in Presidential Debates\n",
    "\n",
    "Your first task is to scrape Presidential Debates from the Commission of Presidential Debates website: http://www.debates.org/index.php?page=debate-transcripts.\n",
    "\n",
    "To do this, you are not allowed to manually look up the URLs that you need, instead you have to scrape them. The root url to be scraped is the one listed above, namely: http://www.debates.org/index.php?page=debate-transcripts\n",
    "\n",
    "\n",
    "1. By using `requests` and `BeautifulSoup` find all the links / URLs on the website that links to transcriptions of **First Presidential Debates** from the years [2012, 2008, 2004, 2000, 1996, 1988, 1984, 1976, 1960]. In total you should find 9 links / URLs tat fulfill this criteria.\n",
    "2. When you have a list of the URLs your task is to create a Data Frame with some statistics (see example of output below):\n",
    "    1. Scrape the title of each link and use that as the column name in your Data Frame. \n",
    "    2. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include `\\` characters in your count, but remove any breakline characters, i.e. `\\n`. You will get credit if your count is +/- 10% from our result.\n",
    "    3. Count how many times the word **war** was used in the different debates. Note that you have to convert the text in a smart way (to not count the word **warranty** for example, but counting **war.**, **war!**, **war,** or **War** etc.\n",
    "    4. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in 3 in order to do this.\n",
    "    \n",
    "**Tips:**\n",
    "\n",
    "___\n",
    "\n",
    "In order to solve question 3 and 4 above it can be useful to work with Regular Expressions and explore methods on strings like `.strip(), .replace(), .find(), .count(), .lower()` etc. Both are very powerful tools to do string processing in Python. To count common words for example I used a `Counter` object and a Regular expression pattern for only words, see example:\n",
    "\n",
    "```python\n",
    "    from collections import Counter\n",
    "    import re\n",
    "\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "```\n",
    "\n",
    "Read more about Regular Expressions here: https://docs.python.org/3/howto/regex.html\n",
    "    \n",
    "    \n",
    "**Example output of all of the answers to EC Question 1:**\n",
    "\n",
    "\n",
    "![pres_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/president_stats.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2. Download and read in specific line from many data sets\n",
    "\n",
    "Scrape the first 27 data sets from this URL http://people.sc.fsu.edu/~jburkardt/datasets/regression/ (i.e.`x01.txt` - `x27.txt`). Then, save the 5th line in each data set, this should be the name of the data set author (get rid of the `#` symbol, the white spaces and the comma at the end). \n",
    "\n",
    "Count how many times (with a Python function) each author is the reference for one of the 27 data sets. Showcase your results, sorted, with the most common author name first and how many times he appeared in data sets. Use a Pandas DataFrame to show your results, see example.\n",
    "\n",
    "**Example output of the answer EC Question 2:**\n",
    "\n",
    "![author_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/data_authors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
